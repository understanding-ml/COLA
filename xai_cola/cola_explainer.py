import string
import numpy as np

from xai_cola.data import BaseData, PandasData
from xai_cola.ml_model import BaseModel
from xai_cola.counterfactual_explainer import CounterFactualExplainer, DiCE

from xai_cola.cola.matching import BaseMatcher, CounterfactualOptimalTransportPolicy
from xai_cola.cola.data_composer import DataComposer
from xai_cola.cola.feature_attributor import Attributor, PSHAP
from xai_cola.counterfactual_refiner import Policy, PshapWithOTmatcher

class COunterfactualwithLimitedActions:

    """
    This class is used for creating COLA(COunterfactual with Limited Actions).

    Parameters:
    -----------
    ml_model: Your pre-trained model, used for prediction. And it should be wrapped in our BaseModel.
    x_factual: The factual instance for which you want to generate counterfactuals. It should be a numpy array.
    x_counterfacutal: The generated counterfactuals(either generated from our provided explainer, or generated by yourself). It should be a numpy array.
    
    matcher: The matcher between factual and counterfactual, it can be "ot": Optimal Transport or "Ect": Exact Match.
    attributor:  The attributor is "pshap"
    Avalues_method: The method to choose the value of q

    """


    def __init__(
            self, 
            data:BaseData,
            ml_model: BaseModel,
            x_factual: np = None, 
            x_counterfactual: np = None,
            limited_actions=None,
            matcher: string = "ot", 
            attributor: string = "pshap",
            Avalues_method: string = "max", 

            ):
        self.data = data
        self.ml_model = ml_model
        self.x_factual = x_factual
        self.x_counterfactual = x_counterfactual
        self.limited_actions = limited_actions

        self.matcher = matcher
        self.attributor = attributor
        self.Avalues_method = Avalues_method
        self.policy = None

    def generate_results(self):
        a = self.choose_policy()
        factual, ce, ace = a.counterfactual_with_limited_actions(self.limited_actions)
        return factual, ce, ace

    def get_matcher(self):
        if self.matcher == "ot":
            return CounterfactualOptimalTransportPolicy(self.x_factual, self.x_counterfactual).compute_prob_matrix_of_factual_and_counterfactual()
        elif self.matcher == "cem":
            pass

    def get_attributor(self):
        if self.attributor == "pshap":
            varphi = PSHAP(ml_model=self.ml_model, x_factual=self.x_factual, x_counterfactual=self.x_counterfactual, joint_prob=self.get_matcher()).calculate_varphi()
            return varphi
        elif self.attributor == "randomshap":
            pass

    def get_data_composer(self):
        return DataComposer(x_factual=self.x_factual, x_counterfactual=self.x_counterfactual, joint_prob=self.get_matcher(), method=self.Avalues_method).calculate_q()

    def choose_policy(self):
        if self.matcher == "ot":
            p = self.get_matcher()
            if self.attributor == "pshap":
                varphi = self.get_attributor()
                q = self.get_data_composer()
                policy = PshapWithOTmatcher(
                    data=self.data, 
                    ml_model=self.ml_model,
                    x_factual=self.x_factual,
                    x_counterfactual=self.x_counterfactual,
                    p=p, 
                    varphi=varphi, 
                    q=q
                    )
                return policy
